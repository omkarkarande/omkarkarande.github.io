{
    "personal_info": {
        "first_name": "Omkar",
        "last_name": "Karande",
        "position": "Computer Science Graduate Student",
        "institute": "University of Southern California",
        "email": [
            "karande[at]usc[dot]edu",
            "omkar.karande[at]outlook[dot]com"
        ],
        "tel": "+1-(213)-378-5624",
        "city": "Los Angeles",
        "state": "CA",
        "pin": "90007"
    },
    "links": {
        "GitHub": "https://github.com/omkarkarande/",
        "LinkedIn": "https://www.linkedin.com/in/omkarkarande/"
    },
    "skills": {
        "programming_languages": [
            "Java",
            "Python",
            "C"
        ],
        "web_technologies": [
            "HTML5",
            "CSS",
            "JavaScript",
            "PHP",
            "AJAX",
            "XML",
            "Bootstrap",
            "AngularJS / Angular2"
        ],
        "mobile_development": [
            "Android"
        ],
        "databases": [
            "MySQL",
            "Oracle"
        ],
        "tools": [
            "Git",
            "Android Studio",
            "NetBeans"
        ],
        "operating_systems": [
            "Windows",
            "Linux",
            "Mac OS"
        ]
    },
    "things_i_know": [
        "Android Development", "Windows Phone Development", "Git", "SVN", "MySQL", "Android Studio", "Visual Studio", "NetBeans", "Unix", "Linux", "Windows", "UX", "PhotoShop", "C++", "Perforce", "InfluxDB", "JIRA", "Confluence", "Telegraf", "Grafana"
    ],
    "timeline": {

        "AUG 2016": [{
            "type": "Work",
            "title": "Research Intern @ DromeBox Labs",
            "desc": [
                "Working on a Deep Learning Computer Vision project."
            ],
            "link": ""
        }],
        "JUN 2016": [{
                "type": "Work",
                "title": "Distributed Data Engineering and System Quality Intern @ Akamai Technologies",
                "desc": [
                    "Designed and developed an ETL and Alerting / Notification system from scratch in Python. It provides a highly configurable deployable system that can keep track of huge amounts of data from multiple sources and notifies the user if any system is misbehaving. It performs additional drill downs on each issue for a more fine tuned experience.",
                    "Wrote a REPL CLI to run SQL - like queries on an HDF5 data store",
                    "Designed and developed an analyzer framework which can be used to write scripts to checks for any known issues in various log files on any given system on the network. The framework intelligently tracks known and unknown issues and validates each known issue by checking for evidence at multiple places before reporting.",
                    "Worked on a script to detect memoy leaks and ramps using the historica data in the data warehouse",
                    "Working on a Full Stack web application using the MEAN stack with Angular2+TypeScript, InfluxDB, and Telegraf."
                ],
                "link": ""
            }

        ],
        "MAY 2016": [{
            "type": "Project",
            "title": "Facial Expression detection using Deep Neural Networks",
            "desc": [
                "Constructed a deep convolutional neural network in Python using Lasagne and Theano libraries",
                "Used stochastic gradient descent for convergence",
                "Made use of CUDA to allow for GPU based acceleration",
                "Achieved an accuracy of 99% for keypoint detection and an accuracy of 80% on expression detection using the keypoints"
            ],
            "link": ""
        }],
        "APR 2016": [{
            "type": "Project",
            "title": "Egocentric Video Indexing and Summarization",
            "desc": [
                "Project aims to summarize and index a video shot on a GoPro or any mounted camera (an 'Egocentric' video) so as to reduce the unwanted monotonous imagery that often take up most of the video time",
                "When shooting using a GoPro, the video captured are the events during the entire duration whenever the camera is ON. This creates a lot of redundancy wasting a lot of space on the video capturing frames with no information content",
                "The summarizer reduces this redundant content in the video by cutting out the unwanted parts and only keeping the sections with high information content in the final video",
                "The indexer clusters frames in buckets to allow for fast image searching. You provide the program with a sample image and it will try to find the image in the video and present with a subsection of the video that contains that image or an image similar to the sample image",
                "Developed in Java and used OpenCV to analyze images, and Java's audio API for processing the audio."
            ]
        }],
        "MAR 2016": [{
                "type": "Project",
                "title": "Wrote a JPEG compression pipeline in Java",
                "desc": [
                    "Wrote a discrete cosine transform filter in Java to compress images. Used concepts of dynamic proramming to make the filter faster.",
                    "Quantized and ran the image through IDCT filter to produce compressed JPEG.",
                    "The program had provision to select different compression levels.",
                    "Implemented a wavelet transform filter to compress the images using JPEG-2000 standard as well."
                ],
                "link": ""
            }

        ],
        "DEC 2015": [{
                "type": "Project",
                "title": "Developing a visualization dashboard using D3.js, LucidWork's Banana and FacetView for the weapons data",
                "desc": [
                    "Developed a D3.js based visualization dashboard for the indexed data in Solr",
                    "Developed a REST framework using NodeJS and AngularJS to communicate with the Solr server to issue a query and fetch the results",
                    "Developed a server endpoint to transform the query results into JSONs that D3 needed to render visualizations",
                    "Developed six visualization techniques which consisted of Spatial data on a bubble map, Scatterplot, Time-Series chart, Flare dendogram, Interactive circle packing, word cloud, and a line chart",
                    "Implemented Banana dashboard and FacetView along with the D3 visualizations"
                ],
                "link": ""
            }

        ],
        "NOV 2015": [{
                "type": "Project",
                "title": "Topical review summarization for restaurant reviews from Yelp",
                "desc": [
                    "The aim of the project was to summarize the reviews for a restaurant into 4 distinct categories viz. Food, Ambiance, Service, and Price.",

                    "Cleaned and preprocessed the dataset provided by Yelp for its dataset challenge. Data consisted of about 22,900 restaurants. Reviews were extracted for these businesses and were preprocessed. Preprocessing involved stemming, tokenization, and stop word removal. Used NLTK for this process",
                    "Developed a script in python using the spacy library to extract words that were tagged as nouns, viz. NN, NNP, NNPS, etc. Using a ranked list of such words, features were extracted pertaining to the above categories",
                    "Developed a script in python to extract sentences from the reviews and obtain a sentiment value for it using NLTK-vader sentiment analysis library. Normalized the sentiment for each sentence using the sentiment value and the user score given for the review",
                    "Developed a script in python to detect the features present in a given sentence using weighted counts of the feature keywords in the sentence. Used a polynomial distance measure to remove false positives. The feature score was then calculated using the weighted average of the sentiment scores across all reviews",
                    "Developed a script using Locu API to detect menu items in the review and give recommendations for good and bad dishes for a given restaurant"
                ],
                "link": ""
            }, {
                "type": "Project",
                "title": "Building an Apache Solr based Search Engine, Ranking Algorithms, and NER for Weapons Datasets",
                "desc": [
                    "Weapons Data gathered was indexed into Solr using Nutch's indexing capabilities.",
                    "Data was passed through configured Tika GeoTopic Parser to retrieve location information from the data and indexed it",
                    "Data was passed through configured Tika UIMA and Apache cTAKES to perform NER on the content to get information about date, time and other entities",
                    "Data was passed through Tika OCR to get textual information overlaid on the images",
                    "Configured the Solr schema to make it compatible with the data getting indexed",
                    "Performed a set of queries to find trends in the data gathered"
                ],
                "link": ""
            }

        ],
        "OCT 2015": [{
            "type": "Project",
            "title": "Crawling and de-duplication of weapon images using Apache Nutch and Tika",
            "desc": [
                "Configured Apache Nutch to perform crawls on firearm websites and classifieds to fetch images of guns",
                "Integrated Selenium with Nutch and developed handlers in Java to interactively load AJAX and JavaScript",
                "Developed a de-duplication algorithm in python to detect duplicate images based on SimHash using the meta-data retrieved from Apache Tika"
            ],
            "link": ""
        }],
        "SEPT 2015": [{
            "type": "Project",
            "title": "Naive Bayes classifier",
            "desc": [
                "Built a naive bayes classifier to detect reveiw sentiment on IMDB reveiws and to detect spam emails",
                "Worked with a labeled dataset of 22,000 emails from the Enron corpus and 25,000 reviews from IMDB",
                "Achieved an accuracy of about 98% for spam detection and 84% for sentiment detection"
            ],
            "link": ""
        }],
        "APR 2015": [{
            "type": "Project",
            "title": "EBay search application",
            "desc": [
                "Developed a responsive website and an Android application using Android Studio to search items on EBay",
                "Wrote and hosted a PHP script on Amazon Elastic Beanstalk to retrieve XML data using EBay’s API and return a JSON representation to the application. Used AJAX for dynamic search results and pagination on the website",
                "Used Facebook’s SDK to implement item sharing on facebook.com"
            ],
            "link": ""
        }],
        "MAR 2015": [{
            "type": "Project",
            "title": "Python implementation of TCP/IP protocol stack",
            "desc": [
                "Developed an application in Python using Raw Sockets to download the contents of the given URL",
                "Worked on packaging and transmitting/receiving TCP packets, sending HTTP requests to web pages, validating checksums, extracting and packaging of payloads, handling retransmission, and sequencing the packets"
            ],
            "link": ""
        }, {
            "type": "Project",
            "title": "SAT solver",
            "desc": [
                "Developed an application in Python to check if a given Conjunctive Normal Form (CNF) statement is satisfiable using the David Putnam Logemann Loveland (DPLL) algorithm",
                "Implemented a converter in Python to convert First Order Logic statements to CNF form"
            ],
            "link": ""
        }],
        "JAN 2015": [{
            "type": "Life",
            "title": "University of Southern California",
            "desc": [
                "Enrolled in the graduate program of Viterbi School of Engineering for my Master's degree in Computer Science",
                "Expected: December 2016",
                "Current GPA: 3.66 / 4.0"
            ],
            "link": ""
        }],
        "OCT 2014": [{
            "type": "Work",
            "title": "Project Intern at Tata Consultancy Services, Mumbai, India",
            "desc": [
                "Worked in a team of 2 to build a prototype routing mechanism leveraging Dual-Stack and Tunneling methods to enable communication between one IPv6 server and multiple IPv6 and IPv4 clients",
                "Aided in the interaction between the SIP stacks of the two protocols",
                "Duration: 3 Months (AUG 2014 - OCT 2014)"
            ],
            "link": ""
        }],
        "AUG 2014": [{
            "type": "Life",
            "title": "Graduated from University of Mumbai",
            "desc": [
                "Earned my Bachelor of Engineering degree in Computer Engineering",
                "Achieved Distinction"
            ],
            "link": ""
        }],
        "MAR 2014": [{
            "type": "Project",
            "title": "ISSAC (Intelligent System for Streamlined Accelerometric Control)",
            "desc": [
                "Worked in a team of 3 to demonstrate the potential use of data from various sensors on wearable devices for gesture recognition",
                "Developed a host application in Java to receive the incoming stream of data from a wearable device and apply real-time pattern recognition on it to detect different gestures",
                "Devised methods to cut off unintentional gestures, clearing unwanted noise, and calibrating various thresholds",
                "Duration: July 2013 - March 2014"
            ],
            "link": "http://goo.gl/Olj5ow"
        }],
        "MAR 2013": [{
            "type": "Project",
            "title": "Online cab hiring system",
            "desc": [
                "Developed a web portal for a cab hiring service with employee and customer endpoints",
                "Technologies used: PHP, JavaScript, CSS and jQuery"
            ],
            "link": ""
        }, {
            "type": "Project",
            "title": "A-Track (Voice based attendance logging application)",
            "desc": [
                "Developed an attendance logger with speech as input",
                "Used Microsoft's specch API (SAPI) for speech detection",
                "Tools: C#, WPF, SAPI"
            ],
            "link": ""
        }]

    }
}
